{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V28","authorship_tag":"ABX9TyMvdgjVXVM7iU0p2CqKOXhh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["!apt-get update\n","from google.colab import drive\n","\n","# Use the 'force_remount' parameter to refresh credentials\n","drive.mount('/drive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sGgtmLmEIjnY","executionInfo":{"status":"ok","timestamp":1720958792993,"user_tz":-180,"elapsed":21909,"user":{"displayName":"DİLBER ÇETİNTAŞ","userId":"17801184400545612195"}},"outputId":"f9c01ecc-c18a-45a7-d2ac-b7384df5fbb2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n","Ign:2 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Get:3 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n","Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n","Get:5 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n","Get:8 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,544 kB]\n","Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Get:10 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,181 kB]\n","Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,998 kB]\n","Hit:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,263 kB]\n","Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,127 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,410 kB]\n","Fetched 17.8 MB in 2s (10.1 MB/s)\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Mounted at /drive/\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o9fedpTbEklH"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50, DenseNet121\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","source":["def cbam_block(input_tensor, ratio=8):\n","    # Channel Attention Module\n","    channel = input_tensor.shape[-1]\n","    shared_layer_one = layers.Dense(channel//ratio,\n","                                    activation='relu',\n","                                    kernel_initializer='he_normal',\n","                                    use_bias=True,\n","                                    bias_initializer='zeros')\n","    shared_layer_two = layers.Dense(channel,\n","                                    kernel_initializer='he_normal',\n","                                    use_bias=True,\n","                                    bias_initializer='zeros')\n","\n","    avg_pool = layers.GlobalAveragePooling2D()(input_tensor)\n","    avg_pool = layers.Reshape((1, 1, channel))(avg_pool)\n","    avg_pool = shared_layer_one(avg_pool)\n","    avg_pool = shared_layer_two(avg_pool)\n","\n","    max_pool = layers.GlobalMaxPooling2D()(input_tensor)\n","    max_pool = layers.Reshape((1, 1, channel))(max_pool)\n","    max_pool = shared_layer_one(max_pool)\n","    max_pool = shared_layer_two(max_pool)\n","\n","    cbam_feature = layers.Add()([avg_pool, max_pool])\n","    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n","\n","    cbam_feature = layers.Multiply()([input_tensor, cbam_feature])\n","\n","    # Spatial Attention Module\n","    avg_pool = layers.Lambda(lambda x: tf.reduce_mean(x, axis=3, keepdims=True))(cbam_feature)\n","    max_pool = layers.Lambda(lambda x: tf.reduce_max(x, axis=3, keepdims=True))(cbam_feature)\n","    concat = layers.Concatenate(axis=3)([avg_pool, max_pool])\n","    cbam_feature = layers.Conv2D(filters=1,\n","                                 kernel_size=7,\n","                                 strides=1,\n","                                 padding='same',\n","                                 kernel_initializer='he_normal',\n","                                 use_bias=False)(concat)\n","    cbam_feature = layers.Activation('sigmoid')(cbam_feature)\n","\n","    cbam_feature = layers.Multiply()([cbam_feature, input_tensor])\n","    return cbam_feature"],"metadata":{"id":"n00lYQZcEs2b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def HybridModel(input_shape, num_classes):\n","    # ResNet50 Model\n","    input_resnet = layers.Input(shape=input_shape, name='input_resnet')\n","    resnet50 = ResNet50(weights='imagenet', include_top=False, input_tensor=input_resnet)\n","    resnet50.trainable = False\n","\n","    # Prefix ResNet50 layer names to avoid conflicts\n","    for layer in resnet50.layers:\n","        layer._name = 'resnet_' + layer.name\n","\n","    resnet_output = resnet50.output\n","    resnet_output = cbam_block(resnet_output)\n","\n","    # DenseNet121 Model\n","    input_densenet = layers.Input(shape=input_shape, name='input_densenet')\n","    densenet121 = DenseNet121(weights='imagenet', include_top=False, input_tensor=input_densenet)\n","    densenet121.trainable = False\n","\n","    # Prefix DenseNet121 layer names to avoid conflicts\n","    for layer in densenet121.layers:\n","        layer._name = 'densenet_' + layer.name\n","\n","    densenet_output = densenet121.output\n","    densenet_output = cbam_block(densenet_output)\n","\n","    # Combine Features\n","    combined = layers.Concatenate()([resnet_output, densenet_output])\n","    combined = layers.GlobalAveragePooling2D()(combined)\n","    combined = layers.Dense(1024, activation='relu')(combined)\n","    combined = layers.Dropout(0.5)(combined)\n","    output = layers.Dense(1, activation='sigmoid')(combined)\n","\n","    model = models.Model(inputs=[input_resnet, input_densenet], outputs=output)\n","    return model"],"metadata":{"id":"HF6fC7NYE13R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_shape = (32, 32, 3)\n","num_classes = 1\n","\n","model = HybridModel(input_shape, num_classes)\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n"],"metadata":{"id":"Ix_vLRfDE7Wf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator  # Import ImageDataGenerator\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.applications import ResNet50, DenseNet121\n","\n","# Görselleri yükleme ve ön işleme\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    '/drive/MyDrive/Colab Notebooks/cifake/train',\n","    target_size=(32, 32),\n","    batch_size=32,\n","    class_mode='binary')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    '/drive/MyDrive/Colab Notebooks/cifake/test',\n","    target_size=(32, 32),\n","    batch_size=32,\n","    class_mode='binary')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVxW9_QMFTPB","executionInfo":{"status":"ok","timestamp":1720961934887,"user_tz":-180,"elapsed":5810,"user":{"displayName":"DİLBER ÇETİNTAŞ","userId":"17801184400545612195"}},"outputId":"6c23829c-1e91-47ea-cff1-13bb8e83b4d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n","Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (2.0.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.7.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n","Found 100000 images belonging to 2 classes.\n","Found 20000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":["# Custom data generator to provide input tensor twice\n","class DualInputGenerator(tf.keras.utils.Sequence):\n","    def __init__(self, generator):\n","        self.generator = generator\n","\n","    def __len__(self):\n","        return len(self.generator)\n","\n","    def __getitem__(self, index):\n","        x, y = self.generator[index]\n","        return [x, x], y\n","\n","train_dual_generator = DualInputGenerator(train_generator)\n","test_dual_generator = DualInputGenerator(test_generator)\n","\n","# Print the length of the generators to verify\n","print(\"Length of train_dual_generator:\", len(train_dual_generator))\n","print(\"Length of test_dual_generator:\", len(test_dual_generator))\n","\n","# Use the tf.data API for optimized data loading\n","def create_dataset(generator):\n","    dataset = tf.data.Dataset.from_generator(\n","        lambda: generator,\n","        output_signature=(\n","            (tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\n","             tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32)),\n","            tf.TensorSpec(shape=(None,), dtype=tf.float32)\n","        )\n","    )\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return dataset\n","\n","train_dataset = create_dataset(train_dual_generator)\n","test_dataset = create_dataset(test_dual_generator)\n","\n","# Define callbacks for model checkpoints and early stopping\n","callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(\n","        filepath='best_model.h5',\n","        monitor='val_loss',\n","        save_best_only=True,\n","        verbose=1),\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss',\n","        patience=3,\n","        verbose=1,\n","        restore_best_weights=True)\n","]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2vex4azFTdGq","executionInfo":{"status":"ok","timestamp":1720979197490,"user_tz":-180,"elapsed":339,"user":{"displayName":"DİLBER ÇETİNTAŞ","userId":"17801184400545612195"}},"outputId":"e5bb3f55-ca12-4529-93bf-b9f425561af3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of train_dual_generator: 3125\n","Length of test_dual_generator: 625\n"]}]},{"cell_type":"code","source":["# Use the tf.data API for optimized data loading\n","def create_dataset(generator):\n","    dataset = tf.data.Dataset.from_generator(\n","        lambda: generator,\n","        output_signature=(\n","            (tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32),\n","             tf.TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32)),\n","            tf.TensorSpec(shape=(None,), dtype=tf.int32)\n","        )\n","    )\n","    dataset = dataset.cache()\n","    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return dataset\n","\n","train_dataset = create_dataset(train_dual_generator)\n","test_dataset = create_dataset(test_dual_generator)\n","\n","# Define callbacks for model checkpoints and early stopping\n","callbacks = [\n","    tf.keras.callbacks.ModelCheckpoint(\n","        filepath='best_model.h5',\n","        monitor='val_loss',\n","        save_best_only=True,\n","        verbose=1),\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss',\n","        patience=3,\n","        verbose=1,\n","        restore_best_weights=True)\n","]\n"],"metadata":{"id":"bNdVCJqtT6hF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model (only if the lengths are non-zero)\n","if len(train_dual_generator) > 0 and len(test_dual_generator) > 0:\n","    model.fit(\n","        train_dataset,\n","        steps_per_epoch=len(train_dual_generator),\n","        epochs=10,\n","        validation_data=test_dataset,\n","        validation_steps=len(test_dual_generator),\n","        callbacks=callbacks)\n","else:\n","    print(\"Error: One or both of the data generators are empty. Check your data paths and ImageDataGenerator setup.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H2A4gPfdTh8L","outputId":"4c88f565-37e0-4702-8c7a-50835dcbdd6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n"]}]},{"cell_type":"code","source":["# Prediction and Evaluation\n","test_steps = test_generator.samples // test_generator.batch_size\n","test_generator.reset()\n","predictions = model.predict(test_dual_generator, steps=test_steps, verbose=1)\n","\n","predicted_classes = (predictions > 0.5).astype(int).reshape(-1)\n","true_classes = test_generator.classes\n","class_labels = list(test_generator.class_indices.keys())\n","\n","# Confusion Matrix\n","cm = confusion_matrix(true_classes, predicted_classes)\n","\n","# Visualize Confusion Matrix\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()"],"metadata":{"id":"0ZskcEAiGVVB"},"execution_count":null,"outputs":[]}]}